{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling the sequential FPL team selection process as a Belief-State Markov Decision Process\n",
    "- For the $i$-th gameweek, we define the following terms:\n",
    "    - $M_i$ is set of matches in gameweek $i$.\n",
    "    - $P_i$ is the set of players available for selection in gameweek $i$.\n",
    "    - $A_i$ is the set of actions available in gameweek $i$, where $a \\in A_i$ is a subset of $P_i$ and observes all team selection constraints.\n",
    "    - $p_i \\in P_i$ is associated with its FPL-designated position $pos(p_i)$ and price $pr(p_i)$.\n",
    "    - $\\tau_p \\in \\tau$ is a system of distributions representing player's performance/influence on the matchplay.\n",
    "    - $O_i$ is the set of match observations in gameweek $i$\n",
    "    - $o \\in O_i$ includes both the result of the matches and the performance of the players in the selected team e.g. goals, assists, clean sheets, yellow cards, red cards, bonus points. The probability of each $o \\in O_i$ is somehow dependent on the players' characteristics ($\\tau$) i.e. a team with strong attackers is more likely to score goals, therefore, $P(o | \\tau)$ is dependent on $\\tau$.\n",
    "    - $R(o, a_{prev}, a_{curr})$ is the reward function, which returns the points scored by the selected team $a_{curr}$, given the match observations $o$. The previous team $a_{prev}$ is also provided to penalize the agent for any player poor player transfers or transfers beyond the allowed number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markov's Decision Process (MDP) \n",
    "- A state $S_i$ would encapsulate\n",
    "    - $M_{i,..., 38}$ - set of upcoming fixtures for that gameweek\n",
    "    - $P_i$ - set of players available for selection\n",
    "    - $o \\in O_{i - 1}$ - the outcome of the previous gameweek\n",
    "    - $\\tau$ - the system of distributions representing players' abilities\n",
    "- An action $A_i$ is the set of teams selectable in gameweek $i$\n",
    "- $R$ is the corresponding reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belief model ($\\tau$):\n",
    "- Represent uncertainty over players' abilities and generate samples $\\tau$ from the distribution $Pr(\\tau | b)$.\n",
    "- Three distributions are used to model the players' abilities:\n",
    "    - $\\rho_p$ - a three-state categorical distribution representing the player's probability of starting a match, being substituted, or not playing at all i.e. (start, sub, unused).\n",
    "    - $\\omega_p$ - a Bernoulli/Binomial distribution over a single trial, representing the probability of a player scoring a goal given he was playiong at the time\n",
    "    - $\\psi_p$ - a Bernoulli distribution representing the probability of a player providing an assist given he was playing at the time\n",
    "- Define prior distributions over the parameters of the above distributions and update them using the match observations $o$ to obtain new posterior distributions.\n",
    "- Use simple closed-form equations e.g. Beta and Dirichlet conjugate priors to update the priors.\n",
    "- Sample from these conjugate distributions to generate $\\tau_p$.\n",
    "- Define hyperparemeters uniformly across all players i.e. $$\\omega_p \\sim Beta(1, 1), \\psi_p \\sim Beta(1, 1),  \\rho_p \\sim Dirichlet(\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{4})$$\n",
    "- Potential to use performance data from previous seasons to define priors\n",
    "- Define 4 global multinomial distributions $S_{pos}$ - one for each position - to describe the distribution of minutes players who play the same position $pos$ are likely to play in a match, given they start the match.\n",
    "- Player absence via injury/suspension or any other reson is modelled by setting the probability of starting and substituting to zero i.e. $Pr(\\rho_p = start) \\text{and} Pr(\\rho_p = sub) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulating the belief-state MDP\n",
    "- The belief state at gameweek $i$, $b_i$, is an instantiation of our belief model, updated with the match observations $O_{i - 1}$.\n",
    "- We observe the posterior player characteristics by updating the belief state in response to an observation $o \\in O_i$ via the Bayes rule: $$Pr(\\tau | b_{i + 1}) \\propto Pr(o | \\tau)Pr(\\tau | b_i)$$\n",
    "- The agent can perform optimally by maximizing the value of the Bellman equation: $$V(b_i) = \\max_{a \\in A_i} Q(b_i, a)$$\n",
    "- The Q-function is defined as: $$Q(b_i, a) = \\int_{\\tau} Pr(\\tau | b_i)  \\int_{o \\in O_i} Pr(o | \\tau) \\left[r_i + \\gamma V(b_{i + 1}) \\right] \\text{dod}\\tau$$\n",
    "- Where:\n",
    "    - $\\gamma \\in [0, 1)$ is the discount factor for future rewards\n",
    "    - $r_i = R(o, a_{prev}, a)$ is the reward function\n",
    "    - $V(b_{i + 1})$ is the value of the next belief state\n",
    "- Solutions to the Bellman equation is intractable due to the size of the outcome space $|O_i|$, the size of the action space $|A_i|$, and the need to consider up to 38 gameweeks in order to calculate Q-values exactly.\n",
    "- We can work around this sampling from $O_i$ and simulating match outcomes to approximate the Q-function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling Outcomes\n",
    "- We describe a model for sampling outcomes for gameweek $i$ from $Pr(O_i | \\tau)$. This is then combined with the belief model described beforehand to obtain a joint distribution of player abilities and match outcomes, thus treating uncertainty in player abilities in a Bayesian manner (observations) $$Pr(O_i | \\tau)Pr(\\tau | b_i)$$\n",
    "- Sampling procedure for a single match that also extends to any other match in the gameweek (it also takes the perspective of the home team, which naturally extends to the away team as well):\n",
    "    - Define $P_H$ and $P_A$ as the set of players available the home and away teams respectively.\n",
    "    - Sample $\\tau_p$ for each player $p \\in P_H$  from the belief model $Pr(\\tau_p | b_i)$\n",
    "    - Randomly select eleven players from $P_H$ in proportion to their probability of starting the match i.e. $Pr(\\rho_p = start)$\n",
    "        - These players constitute the starting lineup $L_H$\n",
    "    - The minute each player leaves the pitch is sampled from the $S_{pos}$ distribution for the player's position\n",
    "    - Each player in $P_H$ and not in $L_H$ is assigned to the set of substitutes $U_H$\n",
    "        - At the start of each minute of the match, we check if any player in $L_H$ is scheduled to be substituted\n",
    "        - If so, we randomly select a player from $U_H$ to replace the outgoing player in proportion to the probability of the player being substituted i.e. $Pr(\\rho_p = sub)$\n",
    "        - The replacement is added to $L_H$ (removed from $U_H$). We further assume that the player being substituted is not substituted again in the same match.\n",
    "        - If a goal is scored according to the underlying team-based model, then it is allocated to player $p$ with probability $Pr(\\omega_p = 1)$ while an assist is allocated to player $p$ with probability $Pr(\\psi_p = 1)$.\n",
    "    - These point estimates may then be used in combination with the MDP reward function $R$ to approximate the immediate reward from performing any action, as well as to guide the exploration of high quality regions of the action space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import GAMEWEEK_COUNT, DATA_FOLDER\n",
    "from gameweek_simulator import GameweekSimulator\n",
    "from player_ability import PlayerAbility\n",
    "from position_minutes import PositionMinutesModel\n",
    "from fpl_env import FPLEnv\n",
    "from bayesianFPLAgent import BayesianFPLAgent\n",
    "from pprint import pprint\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched players: 585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/munene/Desktop/YALE/Spring2025/CSEC491/FPL_AI/model/dixon_coles.py:81: RuntimeWarning: invalid value encountered in log\n",
      "  np.log(self._rho_correction(x, y, lambda_x, mu_y, rho) + epsilon)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1098.7701222730682\n",
      "            Iterations: 57\n",
      "            Function evaluations: 2537\n",
      "            Gradient evaluations: 57\n",
      "Luton Leicester\n",
      "Sheffield Utd Southampton\n",
      "Burnley Leeds\n",
      "{'attack_Arsenal': np.float64(1.5287886992786353),\n",
      " 'attack_Aston Villa': np.float64(0.9847309381026756),\n",
      " 'attack_Bournemouth': np.float64(0.6876779764506612),\n",
      " 'attack_Brentford': np.float64(1.1097354350279998),\n",
      " 'attack_Brighton': np.float64(1.335396148060316),\n",
      " 'attack_Burnley': np.float64(0.9971544569631757),\n",
      " 'attack_Chelsea': np.float64(0.6882985078602293),\n",
      " 'attack_Crystal Palace': np.float64(0.7406474798710736),\n",
      " 'attack_Everton': np.float64(0.5830283154647298),\n",
      " 'attack_Fulham': np.float64(1.0680942169356014),\n",
      " 'attack_Liverpool': np.float64(1.3687432695120643),\n",
      " 'attack_Luton': np.float64(0.9971544569631757),\n",
      " 'attack_Man City': np.float64(1.5873682253120618),\n",
      " 'attack_Man Utd': np.float64(1.1089466464702171),\n",
      " 'attack_Newcastle': np.float64(1.2481124107117276),\n",
      " \"attack_Nott'm Forest\": np.float64(0.7072593587063289),\n",
      " 'attack_Sheffield Utd': np.float64(0.9971544569631757),\n",
      " 'attack_Spurs': np.float64(1.319546907612746),\n",
      " 'attack_West Ham': np.float64(0.8041401962159989),\n",
      " 'attack_Wolves': np.float64(0.4967080290607289),\n",
      " 'defence_Arsenal': np.float64(-1.0488758141305694),\n",
      " 'defence_Aston Villa': np.float64(-1.0177056334288033),\n",
      " 'defence_Bournemouth': np.float64(-0.5947622655520614),\n",
      " 'defence_Brentford': np.float64(-1.0175577839699634),\n",
      " 'defence_Brighton': np.float64(-0.8575814839669609),\n",
      " 'defence_Burnley': np.float64(-0.8656714642431862),\n",
      " 'defence_Chelsea': np.float64(-1.0139127826505272),\n",
      " 'defence_Crystal Palace': np.float64(-0.973243896821028),\n",
      " 'defence_Everton': np.float64(-0.8187148376348614),\n",
      " 'defence_Fulham': np.float64(-0.8737614445194116),\n",
      " 'defence_Liverpool': np.float64(-0.9767630051404336),\n",
      " 'defence_Luton': np.float64(-0.8656714642431862),\n",
      " 'defence_Man City': np.float64(-1.3044466825314363),\n",
      " 'defence_Man Utd': np.float64(-1.0755955845547966),\n",
      " 'defence_Newcastle': np.float64(-1.3547520194647107),\n",
      " \"defence_Nott'm Forest\": np.float64(-0.6347123796545778),\n",
      " 'defence_Sheffield Utd': np.float64(-0.8656714642431862),\n",
      " 'defence_Spurs': np.float64(-0.6772565560589564),\n",
      " 'defence_West Ham': np.float64(-0.843010308026941),\n",
      " 'defence_Wolves': np.float64(-0.8021926656633848),\n",
      " 'home_adv': np.float64(0.29133499581990385),\n",
      " 'rho': np.float64(0.05950956678815913)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n",
      "Sampling: [assist_beta, score_beta, start_sub_unused_dirichlet_dist]\n",
      "Sampling: [minutes_played, minutes_probs]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/fpl_env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'cost'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m fixtures_2023_24_gameweek = fixtures_2023_24[fixtures_2023_24[\u001b[33m\"\u001b[39m\u001b[33mGW\u001b[39m\u001b[33m\"\u001b[39m] == gw_count]\n\u001b[32m     12\u001b[39m player_points_df = GameweekSimulator().simulate_gameweek(\n\u001b[32m     13\u001b[39m     season_start_year=\u001b[33m\"\u001b[39m\u001b[33m2023\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     14\u001b[39m     gameweek=\u001b[38;5;28mstr\u001b[39m(gw_count),\n\u001b[32m     15\u001b[39m     fixtures_df=fixtures_2023_24_gameweek,\n\u001b[32m     16\u001b[39m     position_minutes_df=position_minutes_model.model_df\n\u001b[32m     17\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m reinforcement_learning_env = \u001b[43mFPLEnv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplayer_performance_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplayer_points_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_budget\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_transfers_per_gw\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransfer_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m agent = BayesianFPLAgent()\n\u001b[32m     25\u001b[39m results, state_info = agent.train(env=reinforcement_learning_env, num_episodes=\u001b[32m1000\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/YALE/Spring2025/CSEC491/FPL_AI/model/fpl_env.py:71\u001b[39m, in \u001b[36mFPLEnv.__init__\u001b[39m\u001b[34m(self, player_performance_samples, initial_budget, max_transfers_per_gw, transfer_penalty)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28mself\u001b[39m.action_space = gym.spaces.Discrete(\u001b[38;5;28mself\u001b[39m._action_subspace_size)\n\u001b[32m     53\u001b[39m \u001b[38;5;28mself\u001b[39m.observation_space = gym.spaces.Dict(\n\u001b[32m     54\u001b[39m     {\n\u001b[32m     55\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbudget\u001b[39m\u001b[33m\"\u001b[39m: gym.spaces.Box(low=\u001b[32m0\u001b[39m, high=initial_budget, shape=(\u001b[32m1\u001b[39m,)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRANDOM_SEED\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/YALE/Spring2025/CSEC491/FPL_AI/model/fpl_env.py:81\u001b[39m, in \u001b[36mFPLEnv.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28mself\u001b[39m._total_points = \u001b[32m0\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28mself\u001b[39m._free_transfers = \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28mself\u001b[39m._team = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_team\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[38;5;28mself\u001b[39m._bench = \u001b[38;5;28mself\u001b[39m._select_bench()\n\u001b[32m     83\u001b[39m \u001b[38;5;28mself\u001b[39m._playing = \u001b[38;5;28mself\u001b[39m._team[~\u001b[38;5;28mself\u001b[39m._team[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m].isin(\u001b[38;5;28mself\u001b[39m._bench[\u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m])]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/YALE/Spring2025/CSEC491/FPL_AI/model/fpl_env.py:170\u001b[39m, in \u001b[36mFPLEnv._initialize_team\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[33;03m- Select a team of 15 players with the highest sampled points per unit cost in the\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[33;03m first gameweek based on FPL's rules:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    165\u001b[39m \u001b[33;03m    - budget - 100 million Euros\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;66;03m# Greedily sort players using their expected points per unit cost\u001b[39;00m\n\u001b[32m    168\u001b[39m \u001b[38;5;28mself\u001b[39m._sampled_gameweek_player_performance[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = (\n\u001b[32m    169\u001b[39m     \u001b[38;5;28mself\u001b[39m._sampled_gameweek_player_performance[\u001b[33m\"\u001b[39m\u001b[33mpoints\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     / \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sampled_gameweek_player_performance\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    171\u001b[39m )\n\u001b[32m    172\u001b[39m sorted_sampled_gameweek_player_performance = (\n\u001b[32m    173\u001b[39m     \u001b[38;5;28mself\u001b[39m._sampled_gameweek_player_performance.sort_values(\n\u001b[32m    174\u001b[39m         by=\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m, inplace=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    175\u001b[39m     )\n\u001b[32m    176\u001b[39m )\n\u001b[32m    178\u001b[39m team_counts = {team_id: \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m team_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m21\u001b[39m)}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/fpl_env/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/fpl_env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'cost'"
     ]
    }
   ],
   "source": [
    "fixtures_2023_24 = pd.read_csv(filepath_or_buffer=f\"{DATA_FOLDER}/2023-24/fixtures.csv\")\n",
    "\n",
    "# Bayesian model for players' ability to (start, get subbed, or not play), score, and assist\n",
    "player_ability_model = PlayerAbility(season_start_year=\"2023\", gameweek=\"0\")\n",
    "\n",
    "# Bayesian model for players' game minutes per position \n",
    "position_minutes_model = PositionMinutesModel()\n",
    "for gw_count in range(1, GAMEWEEK_COUNT + 1, 1):\n",
    "    # Filter fixtures for specified gameweek\n",
    "    fixtures_2023_24_gameweek = fixtures_2023_24[fixtures_2023_24[\"GW\"] == gw_count]\n",
    "\n",
    "    player_points_df = GameweekSimulator().simulate_gameweek(\n",
    "        season_start_year=\"2023\", \n",
    "        gameweek=str(gw_count),\n",
    "        fixtures_df=fixtures_2023_24_gameweek,\n",
    "        position_minutes_df=position_minutes_model.model_df\n",
    "    )\n",
    "    reinforcement_learning_env = FPLEnv(\n",
    "        player_performance_samples=player_points_df,\n",
    "        initial_budget=100.0,\n",
    "        max_transfers_per_gw=1,\n",
    "        transfer_penalty=4\n",
    "    )\n",
    "    agent = BayesianFPLAgent()\n",
    "    results, state_info = agent.train(env=reinforcement_learning_env, num_episodes=1000)\n",
    "    pprint(state_info)\n",
    "    print(f\"Gameweek: {gw_count}; Projected points: {results[-1]}\")\n",
    "    print(\"---------------------------------------------------------------------------------------\")\n",
    "    # Update player ability priors with completed gameweek's data\n",
    "    player_ability_model.update_model()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
